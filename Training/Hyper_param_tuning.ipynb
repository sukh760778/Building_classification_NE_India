{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_aug(img_shape: tuple[int,int], val_split: float, batch_size, data_dir: str):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "      img_shape: shape of the images required\n",
    "      val_split: percentage of dataset required for validation\n",
    "      batch_size: batch_size\n",
    "      data_dir: the directory that stores the raw dataset\n",
    "\n",
    "  Splits the data into two augmented datasets for training and validation\n",
    "  Uses tf.keras.preprocessing and seed=123 for the same\n",
    "\n",
    "  Returns: (train_dataset, validation_dataset)\n",
    "  \"\"\"\n",
    "  train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=val_split,\n",
    "        subset=\"training\",\n",
    "        seed=123,\n",
    "        image_size=img_shape,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "  val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=val_split,\n",
    "        subset=\"validation\",\n",
    "        seed=123,\n",
    "        image_size=img_shape,\n",
    "        batch_size=batch_size)\n",
    "  return (train_ds,val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Init_model(image_shape: tuple[int,int]):\n",
    "  \"\"\"\n",
    "  ### This function is currently using InceptionV3 for the pretrained model. Customise as you see fit for other models\n",
    "  ## There are preloaded models in this function, but commented out. \n",
    "  ## Comment and uncomment as you see fit\n",
    "  Inputs:\n",
    "    image_shape: the shape of the images given as input\n",
    "\n",
    "  Creates an instance of a Sequential model and adds custom layers\n",
    "\n",
    "  Returns: tensorflow.keras.models.Sequential\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  incep_model = Sequential()\n",
    "\n",
    "  pretrained_model = tf.keras.applications.InceptionV3(\n",
    "      include_top=False,\n",
    "      weights=\"imagenet\",\n",
    "      input_shape=(image_shape[0],image_shape[1],3),\n",
    "      pooling='avg',\n",
    "      classes=4,\n",
    "      classifier_activation=\"softmax\",\n",
    "  )\n",
    "\n",
    "  # pretrained_model = tf.keras.applications.EfficientNetB0(\n",
    "  #     include_top=False,\n",
    "  #     weights=\"imagenet\",\n",
    "  #     input_shape=(image_shape[0],image_shape[1],3),\n",
    "  #     pooling='avg',\n",
    "  #     classes=4,\n",
    "  #     classifier_activation=\"softmax\",\n",
    "  # )\n",
    "\n",
    "  # pretrained_model = tf.keras.applications.MobileNet(\n",
    "  #       include_top=False,\n",
    "  #       weights=\"imagenet\",\n",
    "  #       input_shape=(image_shape[0],image_shape[1],3),\n",
    "  #       pooling='avg',\n",
    "  #       classes=4,\n",
    "  #       classifier_activation=\"softmax\",\n",
    "  #   )\n",
    "\n",
    "  # pretrained_model = tf.keras.applications.Xception(\n",
    "  #       include_top=False,\n",
    "  #       weights=\"imagenet\",\n",
    "  #       input_shape=(image_shape[0],image_shape[1],3),\n",
    "  #       pooling='avg',\n",
    "  #       classes=4,\n",
    "  #       classifier_activation=\"softmax\",\n",
    "  #   )\n",
    "\n",
    "\n",
    "  # Freeze the layers of the pre_trained model\n",
    "  for layer in pretrained_model.layers:\n",
    "      layer.trainable = False\n",
    "\n",
    "  # Define your Sequential model and add the InceptionV3\n",
    "  incep_model.add(pretrained_model)\n",
    "  # Add additional layers\n",
    "  incep_model.add(Flatten()) \n",
    "  incep_model.add(Dense(1024, activation='relu'))\n",
    "  incep_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "  return incep_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inBetween(A, centre) -> bool: # Between 10% of the value is close enough\n",
    "  \"\"\"\n",
    "  Inputs: \n",
    "    A: Current accuracy\n",
    "    centre: previous best accuracy\n",
    "\n",
    "  Function that checks if the accuracy is good enough to record hyper parameters and move on\n",
    "  Saves training resources\n",
    "\n",
    "  returns: bool\n",
    "  \"\"\"\n",
    "  if(A>centre and A<1.1*centre):\n",
    "    return True\n",
    "  elif(A<centre and A>0.9*centre):\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(lr, loss_type, image_shape: tuple[int,int], train_ds, val_ds, epochs = 4):\n",
    "  \"\"\"\n",
    "  Inputs : \n",
    "    lr: learning rate\n",
    "    loss_type: loss type (sparse_categorical_crossentropy, etc.)\n",
    "    image_shape: image shape tuple(int, int) (pix_y, pix_x)\n",
    "    train_ds: dtataset containing the data for training\n",
    "    val_ds: dataset for validation\n",
    "    epochs: the number of epochs the accuracy calculator will try for (Default = 4)\n",
    "    \n",
    "  \"\"\"\n",
    "  incep_model = Init_model(image_shape)\n",
    "  incep_model.compile(optimizer=Adam(learning_rate=lr), loss=loss_type, metrics=['accuracy'])\n",
    "  history = incep_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    )\n",
    "\n",
    "  val_acc = history.history['val_accuracy']\n",
    "\n",
    "  return val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_param_optim(data_dir, val_split = 0.3, loss_type = 'sparse_categorical_crossentropy', epochs= 4):\n",
    "  #{'val_acc': 0.7018, 'lr': 5e-05, 'batch_size': 8, 'img_shape': (512, 512)}\n",
    "  \"\"\"\n",
    "    Inputs: \n",
    "      data_dir: directory of raw_data\n",
    "      val_split: percentage of dataset segregated for validation (Default=0.3)\n",
    "      loss_type: the type functions we calculate loss using (Default=sparse_categorical_crossentropy)\n",
    "      epochs: No. of epochs the function will try for (Default=4)\n",
    "\n",
    "    Returns: Dict # Returns the hyperparameters that resulted in the best validation accuracy\n",
    "  \"\"\"\n",
    "  hyper_P = {\n",
    "    'val_acc':-float('inf'),\n",
    "    'lr':0,\n",
    "    'batch_size':0,\n",
    "    'img_shape':(0,0)\n",
    "    }\n",
    "  \n",
    "  past_success = [hyper_P]\n",
    "  already_tried = [\n",
    "      (hyper_P['batch_size'],\n",
    "       hyper_P['img_shape'][0],\n",
    "       hyper_P['lr'])\n",
    "      ]\n",
    "  lr = hyper_P['lr']\n",
    "  iter = -1 # change this to -1 for newer runs\n",
    "  while (iter<15):\n",
    "    iter+=1\n",
    "    if (iter >= 0 and iter < 4): \n",
    "      lr = choice([1e-2,1e-3,1e-4,1e-5])\n",
    "    elif (iter >= 4 and iter < 9):\n",
    "      lr = choice([lr*2,lr/2])\n",
    "    elif (iter >= 9):\n",
    "      lr = choice([lr/3,lr*2/3,lr*4/3,lr*5/3])\n",
    "\n",
    "    batch_size = choice([8,16,32])\n",
    "    img_size = choice([180,256,512])\n",
    "\n",
    "\n",
    "    if((batch_size,img_size,lr) in already_tried):\n",
    "      continue\n",
    "    else:\n",
    "      already_tried.append((batch_size,img_size,lr))\n",
    "\n",
    "    img_shape=(img_size,img_size)\n",
    "\n",
    "    train_ds,val_ds = img_aug(img_shape,val_split,batch_size,data_dir) #img_shape,val_split,batch_size\n",
    "\n",
    "    print(f'Testing :  Batch_Size: {batch_size}, Img_Shape: {img_size}, Learning Rate: {lr}')\n",
    "\n",
    "    acc = max(calc_acc(lr, loss_type, img_shape, train_ds, val_ds, epochs)) #lr, batch_size, loss_type, image_shape, train_ds, val_ds, epochs = 4 \n",
    "    print(\"Accuracy: \",acc)\n",
    "    \n",
    "    if acc>hyper_P['val_acc']:\n",
    "      hyper_P = {\n",
    "        'val_acc':acc,\n",
    "        'lr':lr,\n",
    "        'batch_size':batch_size,\n",
    "        'img_shape':img_shape\n",
    "        }\n",
    "      past_success = [hyper_P]\n",
    "    elif inBetween(acc, hyper_P['val_acc']):\n",
    "      hyper_P = {\n",
    "        'val_acc':acc,\n",
    "        'lr':lr,\n",
    "        'batch_size':batch_size,\n",
    "        'img_shape':img_shape\n",
    "        }\n",
    "      past_success.append(hyper_P)\n",
    "      if(len(past_success)>2 and iter>=11): # Arbitrary ## Checks if the result is already good enough\n",
    "        return hyper_P,past_success\n",
    "    print(f'Best: --{past_success}--')\n",
    "  return past_success[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'/processed_unaugmented'\n",
    "dir_txt = r'/hyperparams_incep.txt' # file where the hyperparameters are stored\n",
    "\n",
    "hyper_params = hyper_param_optim(data_dir)\n",
    "print(hyper_params)\n",
    "\n",
    "from datetime import date\n",
    "now = date.today().isoformat()\n",
    "\n",
    "from pathlib import Path\n",
    "Path(data_dir).mkdir(exist_ok=True)\n",
    "\n",
    "with open(dir_txt, 'a') as f:\n",
    "    f.write(f'Test done on {now}\\nHyperparameters found: \\n{hyper_params}\\n')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
